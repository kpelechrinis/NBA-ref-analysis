> # ---- start --------------------------------------------------------------
> 
> library(tidyverse)
── Attaching core tidyverse packages ────────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.0     ✔ readr     2.1.4
✔ forcats   1.0.0     ✔ stringr   1.5.0
✔ ggplot2   3.4.1     ✔ tibble    3.2.0
✔ lubridate 1.9.2     ✔ tidyr     1.3.0
✔ purrr     1.0.1     
── Conflicts ──────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package to force all conflicts to become errors
> 
> # Create a directory for the data
> local_dir     <- "data/"
> if (!file.exists(local_dir)) dir.create(local_dir, recursive = T)
> 
> # ---- download -----------------------------------------------------------
> 
> # Set commit for the particular version of L2M data, 2023-04-20 update
> commit <- "f2e89abcbbd1dd6ad0745525bd5405ef31d43432" 
> 
> l2m_url <- paste0("https://raw.githubusercontent.com/atlhawksfanatic/L2M/",
+                   commit,
+                   "/1-tidy/L2M/L2M.csv")
> l2m_file <- paste0(local_dir, "L2M_", commit, ".csv")
> 
> if (!file.exists(l2m_file)) download.file(l2m_url, l2m_file)
> 
> l2m <- read_csv(l2m_file)
Rows: 74144 Columns: 42                                                                                              
── Column specification ──────────────────────────────────────────────────────────
Delimiter: ","
chr  (28): period, call_type, committing, disadvantaged, decision, comments, g...
dbl  (10): page, away_score, home_score, attendance, committing_min, disadvant...
lgl   (1): playoff
dttm  (1): scrape_time
date  (1): date
time  (1): time

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> 
> # ---- setup --------------------------------------------------------------
> 
> # Variables to adjust
> szn = 2014:2022
> var_group = "call_type" # really should just be call as it's more concise
> n = 100
> set.seed(324)
> 
> # Create event space from L2M sample (ie ignores CNC and maybe more)
> l2m_sample <- l2m |>
+   # Uncomment for the blank decisions to be INC
+   # mutate(decision = ifelse(is.na(decision), "INC", decision)) |>
+   filter(decision %in% c("IC", "INC", "CC"),
+          season %in% szn)
> 
> # Get sample probabilities for the grouping variable
> sample_probs <- l2m_sample |>
+   group_by(!!rlang::sym(var_group)) |>
+   summarise(
+     n = n(),
+     p1 = sum(decision %in% c("INC"), na.rm = T) / n,
+     p2 = sum(decision %in% c("IC", "INC"), na.rm = T) / n
+   )
> 
> # From the sample, event space results based on home status
> sample_t <- l2m_sample |>
+   mutate(
+     result = case_when(
+       committing_side == "home" & decision == "INC" ~ "inch",
+       committing_side == "home" & decision == "IC" ~ "icc",
+       disadvantaged_side == "home" & decision == "INC" ~ "incd",
+       disadvantaged_side == "home" & decision == "IC" ~ "icd",
+       T ~ "neither"
+     )
+   ) |>
+   group_by(result) |>
+   tally() |>
+   pivot_wider(names_from = "result", values_from = "n") |>
+   mutate(t_real = (inch + icd) - (incd + icc))
> 
> # Merge sample probabilities with the sample itself, easier to sim from
> l2m_to_sample <- left_join(l2m_sample, sample_probs)
Joining with `by = join_by(call_type)`
> 
> # For n simulations, take sample dataset and simulate for every event a random
> #  number between 0 and 1 to determine if the event falls within the bounds of
> #  an incorrect no-call, incorrect call, or correct call.
> sample_simmed <- map(1:n, function(x) {
+   print(paste0("sampled ", x, " at ", Sys.time()))
+   l2m_to_sample |>
+     mutate(
+       monte = runif(n(), 0, 1),
+       result = case_when(
+         committing_side == "home" & monte < p1 ~ "inch",
+         committing_side == "home" & monte < p2 ~ "icc",
+         disadvantaged_side == "home" & monte < p1 ~ "incd",
+         disadvantaged_side == "home" & monte < p2 ~ "icd",
+         T ~ "neither"
+       )
+     ) |>
+     group_by(result) |>
+     tally() |>
+     pivot_wider(names_from = "result", values_from = "n") |>
+     mutate(t_sim = (inch + icd) - (incd + icc))
+ }) |>
+   bind_rows()
[1] "sampled 1 at 2023-04-21 23:44:50"
[1] "sampled 2 at 2023-04-21 23:44:50"
[1] "sampled 3 at 2023-04-21 23:44:50"
[1] "sampled 4 at 2023-04-21 23:44:50"
[1] "sampled 5 at 2023-04-21 23:44:50"
[1] "sampled 6 at 2023-04-21 23:44:50"
[1] "sampled 7 at 2023-04-21 23:44:50"
[1] "sampled 8 at 2023-04-21 23:44:50"
[1] "sampled 9 at 2023-04-21 23:44:50"
[1] "sampled 10 at 2023-04-21 23:44:50"
[1] "sampled 11 at 2023-04-21 23:44:50"
[1] "sampled 12 at 2023-04-21 23:44:50"
[1] "sampled 13 at 2023-04-21 23:44:51"
[1] "sampled 14 at 2023-04-21 23:44:51"
[1] "sampled 15 at 2023-04-21 23:44:51"
[1] "sampled 16 at 2023-04-21 23:44:51"
[1] "sampled 17 at 2023-04-21 23:44:51"
[1] "sampled 18 at 2023-04-21 23:44:51"
[1] "sampled 19 at 2023-04-21 23:44:51"
[1] "sampled 20 at 2023-04-21 23:44:51"
[1] "sampled 21 at 2023-04-21 23:44:51"
[1] "sampled 22 at 2023-04-21 23:44:51"
[1] "sampled 23 at 2023-04-21 23:44:51"
[1] "sampled 24 at 2023-04-21 23:44:51"
[1] "sampled 25 at 2023-04-21 23:44:51"
[1] "sampled 26 at 2023-04-21 23:44:51"
[1] "sampled 27 at 2023-04-21 23:44:51"
[1] "sampled 28 at 2023-04-21 23:44:51"
[1] "sampled 29 at 2023-04-21 23:44:51"
[1] "sampled 30 at 2023-04-21 23:44:51"
[1] "sampled 31 at 2023-04-21 23:44:51"
[1] "sampled 32 at 2023-04-21 23:44:51"
[1] "sampled 33 at 2023-04-21 23:44:52"
[1] "sampled 34 at 2023-04-21 23:44:52"
[1] "sampled 35 at 2023-04-21 23:44:52"
[1] "sampled 36 at 2023-04-21 23:44:52"
[1] "sampled 37 at 2023-04-21 23:44:52"
[1] "sampled 38 at 2023-04-21 23:44:52"
[1] "sampled 39 at 2023-04-21 23:44:52"
[1] "sampled 40 at 2023-04-21 23:44:52"
[1] "sampled 41 at 2023-04-21 23:44:52"
[1] "sampled 42 at 2023-04-21 23:44:52"
[1] "sampled 43 at 2023-04-21 23:44:52"
[1] "sampled 44 at 2023-04-21 23:44:52"
[1] "sampled 45 at 2023-04-21 23:44:52"
[1] "sampled 46 at 2023-04-21 23:44:52"
[1] "sampled 47 at 2023-04-21 23:44:52"
[1] "sampled 48 at 2023-04-21 23:44:52"
[1] "sampled 49 at 2023-04-21 23:44:52"
[1] "sampled 50 at 2023-04-21 23:44:52"
[1] "sampled 51 at 2023-04-21 23:44:52"
[1] "sampled 52 at 2023-04-21 23:44:52"
[1] "sampled 53 at 2023-04-21 23:44:52"
[1] "sampled 54 at 2023-04-21 23:44:52"
[1] "sampled 55 at 2023-04-21 23:44:53"
[1] "sampled 56 at 2023-04-21 23:44:53"
[1] "sampled 57 at 2023-04-21 23:44:53"
[1] "sampled 58 at 2023-04-21 23:44:53"
[1] "sampled 59 at 2023-04-21 23:44:53"
[1] "sampled 60 at 2023-04-21 23:44:53"
[1] "sampled 61 at 2023-04-21 23:44:53"
[1] "sampled 62 at 2023-04-21 23:44:53"
[1] "sampled 63 at 2023-04-21 23:44:53"
[1] "sampled 64 at 2023-04-21 23:44:53"
[1] "sampled 65 at 2023-04-21 23:44:53"
[1] "sampled 66 at 2023-04-21 23:44:53"
[1] "sampled 67 at 2023-04-21 23:44:53"
[1] "sampled 68 at 2023-04-21 23:44:53"
[1] "sampled 69 at 2023-04-21 23:44:53"
[1] "sampled 70 at 2023-04-21 23:44:53"
[1] "sampled 71 at 2023-04-21 23:44:53"
[1] "sampled 72 at 2023-04-21 23:44:53"
[1] "sampled 73 at 2023-04-21 23:44:53"
[1] "sampled 74 at 2023-04-21 23:44:53"
[1] "sampled 75 at 2023-04-21 23:44:53"
[1] "sampled 76 at 2023-04-21 23:44:53"
[1] "sampled 77 at 2023-04-21 23:44:54"
[1] "sampled 78 at 2023-04-21 23:44:54"
[1] "sampled 79 at 2023-04-21 23:44:54"
[1] "sampled 80 at 2023-04-21 23:44:54"
[1] "sampled 81 at 2023-04-21 23:44:54"
[1] "sampled 82 at 2023-04-21 23:44:54"
[1] "sampled 83 at 2023-04-21 23:44:54"
[1] "sampled 84 at 2023-04-21 23:44:54"
[1] "sampled 85 at 2023-04-21 23:44:54"
[1] "sampled 86 at 2023-04-21 23:44:54"
[1] "sampled 87 at 2023-04-21 23:44:54"
[1] "sampled 88 at 2023-04-21 23:44:54"
[1] "sampled 89 at 2023-04-21 23:44:54"
[1] "sampled 90 at 2023-04-21 23:44:54"
[1] "sampled 91 at 2023-04-21 23:44:54"
[1] "sampled 92 at 2023-04-21 23:44:54"
[1] "sampled 93 at 2023-04-21 23:44:54"
[1] "sampled 94 at 2023-04-21 23:44:54"
[1] "sampled 95 at 2023-04-21 23:44:54"
[1] "sampled 96 at 2023-04-21 23:44:54"
[1] "sampled 97 at 2023-04-21 23:44:54"
[1] "sampled 98 at 2023-04-21 23:44:54"
[1] "sampled 99 at 2023-04-21 23:44:55"
[1] "sampled 100 at 2023-04-21 23:44:55"
> 
> # Summarize simulation
> sample_simmed |>
+   mutate(t_real = sample_t$t_real) |>
+   summarise(
+     t_real_mean = mean(t_real),
+     t_sim_mean = mean(t_sim),
+     effect = t_real_mean - t_sim_mean,
+     emp_pval = sum(t_sim >= t_real) / n,
+     sims = n
+   )
# A tibble: 1 × 5
  t_real_mean t_sim_mean effect emp_pval  sims
        <dbl>      <dbl>  <dbl>    <dbl> <dbl>
1         361       209.   152.     0.01   100